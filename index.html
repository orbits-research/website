<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="ORBITS: Online Real-time Benchmarking of Indicator Time Series">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ORBITS: Online Real-time Benchmarking of Indicator Time Series</title>



  <!-- custom fonts -->
  <link rel="stylesheet" type="text/css"
    href="https://cdn.rawgit.com/dreampulse/computer-modern-web-font/master/fonts.css">
  <link href="https://fonts.cdnfonts.com/css/proxima-nova-2" rel="stylesheet">
  <!-- end custom fonts -->

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" type="ico" href="./static/images/favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
    integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
    integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz"
    crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
    crossorigin="anonymous"></script>
  <script>

    function whenAvailable(name, callback) {
      var interval = 10; // ms
      window.setTimeout(function () {
        if (window[name]) {
          callback(window[name]);
        } else {
          whenAvailable(name, callback);
        }
      }, interval);
    }

    whenAvailable("katex", function (t) {
      // Put your macros below, key will be replaced by the corresponding macro
      console.log('Rendering latex...')

      katex.__defineMacro(`\\cx`, `\\mathcal{ X }`)
      katex.__defineMacro(`\\cy`, `\\mathcal{ Y }`)
      katex.__defineMacro(`\\cf`, `\\mathcal{ F }`)
      katex.__defineMacro(`\\ch`, `\\mathcal{ H }`)
      katex.__defineMacro(`\\ptest`, `p_{ \\mathrm{ test } }`)
      katex.__defineMacro(`\\softmax`, `\\mathrm{ softmax }`)
      katex.__defineMacro(`\\E`, `\\mathbb{ E }`)

      katex.__defineMacro(`\\dist`, `\\mathcal{ D }`)
      katex.__defineMacro(`\\distgen`, `\\overline{ \mathcal{ D } }`)
      katex.__defineMacro(`\\distspec`, `\\mathcal{ D } _i`)
      renderMathInElement(document.body)
    });
  </script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ORBITS: Online Real-time Benchmarking of Indicator Time Series</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="">Anonymous</a>
                <!-- <sup>1</sup> -->
              </span>

            </div>

            <!-- <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Anonymous</span>

            </div> -->



            <div class="column has-text-centered">
              <div class="publication-links">

              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h2 class="subtitle has-text-centered">
        </h2>
      </div>
    </div>
  </section>


  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <!-- <h2 class="title is-3">Main Result</h2> -->
        <div class="columns is-centered has-text-centered">
          <div></div>
          <div class="column is-full-width">
            <img src="./static/images/rating_temp.png" alt="chart">
            <p style="margin: 1em 0">
              Ratings of our autoregressive decoder-only transformer, ChessFormer, over several different temperatures.
              Each model is trained only on games with players up to a certain rating (1000, 1300, 1500),
              respectively. Interestingly, ChessFormer 1500 is unable to transcend at test time, a result that we
              further analyze in the paper.
            </p>
          </div>
          <br />
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Generative models are trained with the simple objective of imitating the conditional probability
              distribution induced by
              the data they are trained on. Therefore, when trained on data generated by human experts, we may not
              expect the
              artificial model to outperform the experts on their original objectives. Yet it is often observed in
              practice that such
              models possess surprising capabilities, suggesting that they might surpass human experts in certain
              aspects.
            </p>
            <p>
              In this
              work, we study the phenomenon of <em>ORBITS</em>: when a generative model achieves capabilities
              that surpass
              the abilities
              of the human experts generating its data. We demonstrate ORBITS by training an autoregressive
              transformer to play
              chess from game transcripts, and show that the trained model can sometimes achieve better Glicko-2 scores
              compared to
              the players in the dataset.
            </p>
            <p>
              We theoretically prove that ORBITS is enabled by low-temperature
              sampling, and
              rigorously assess this experimentally. Finally, we discuss other forms of ORBITS, laying the
              groundwork for
              future investigation of this phenomenon in a broader setting.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>


    <div style="height: 100px;"></div>

    <div class="container is-max-desktop content">
      <h2 class="title is-3">How ORBITS Works through Low-Temperature Sampling</h2>


      Visualizing the denoising effects of low temperature on the action distribution: an example of ChessFormer
      shifting
      probability mass towards the high reward move of trapping the queen with the rook as the temperature \( \tau \)
      decreases.
      Opacity of the red arrows represent the probability mass given to different moves. The color of the square
      represent the
      reward that would be given for taking the action that moves the given piece to that state. Purple here is high
      reward,
      while blue is low.

      <div class="columns is-centered has-text-centered" style="margin-top: 15px;">
        <div class="column is-full-width">
          <img src="./static/images/advantage-analysis.png" alt="chart">
        </div>
        <br />
      </div>

      In the figure below, we plot the distribution of the change in expected reward across two different interventions:
      setting
      \( \tau
      \rightarrow .75 \) and \( \tau \rightarrow 0.001 \) by
      running the
      Stockfish analysis engine across 100 games played at 0.001 temperature against Stockfish level 1, as well as
      sampling 100 potential moves per move per game to gather an empirical probability distribution with n = 382100
      total
      samples per \( \tau \) (38.2 moves on average per game). We find that \( \tau \rightarrow 0.001 \) improves the
      expected
      reward (probability of winning) by an average of <strong>2.17%</strong>, whilst \( \tau \rightarrow 0.75 \)
      improves by
      1.01%. Here, we define the "favor" of \( f' \) over \( f \) in \( x \) as the change in the reward function by
      following some \( f' \) rather
      than \( f \) for a given input \( x \): \( F(f', f ; x) = r_x(f') - r_x(f) \).

      <div class="columns is-centered has-text-centered" style="margin-top: 15px;">
        <div class="column is-full-width">
          <img src="./static/images/adv-gain-dist-flat.png" alt="chart">
        </div>
        <br />
      </div>

    </div>


    <div class="container is-max-desktop content">
      <h2 class="title is-3">When ORBITS Happens</h2>


      <h3>Formal Definition of ORBITS</h3>

      <div class="columns ">
        <div class="column is-full-width">

          In a setting of \( f_1, \dots, f_k \in \cf \) experts, \( \cx \) input
          distribution, and \( p \in P(\cx) \), we define <em>ORBITS</em> to be:

          \[

          R_{p_{test}}(\hat{f}) > \max_{i \in [k]} R_{\ptest}(f_i).

          \]


          Here \( R_{\ptest}(f) \) is the expected reward of a predictor \( f \) on the test distribution \( \ptest \),
          and \( r(x, y) \) is the reward function:

          <div class="largescreen">
            \[

            R_{\ptest}(f) = \mathbb{E}_{x \sim \ptest}\left[r_x(f)\right], ~~~\mathrm{where}~~r_x(f) = \mathbb{E}_{y
            \sim
            f(\cdot |
            x)} \left[r(x,y)\right].

            \]
          </div>
          <div class="smallscreen">
            \[

            R_{\ptest}(f) = \mathbb{E}_{x \sim \ptest}\left[r_x(f)\right],
            \\
            ~~~\mathrm{where}~~r_x(f) = \mathbb{E}_{y
            \sim
            f(\cdot |
            x)} \left[r(x,y)\right].

            \]
          </div>
          In other words, <em>ORBITS</em> describes cases where the learned predictor performs better (achieves
          better reward) than
          the best expert generating the data.
          Note that we are focusing on an idealized setting, where the learner has access to infinite amount of data
          from the
          distribution \( \dist \) , and can arbitrarily choose any function to fit the distribution (not limited to a
          particular
          choice of architecture or optimization constraints). As we will show, even in this idealized setting,
          ORBITS can
          be impossible to achieve without further modifying the disribution.

        </div>

      </div>
      <h3>ORBITS is possible with Low-Temperature Sampling</h3>

      <div class="columns ">
        <div class="column is-full-width">


          Now, we consider a temperature sampling scheme over the learned function \( \hat{f} \). Namely, for some
          temperature \( \tau >
          0 \), and some probability distribution \( q \in P(\cy) \), denote the softmax operator with temperature \(
          \tau \) by
          \( \softmax(q;\tau) \in P(\cy) \) such that

          \[
          \softmax(q; \tau)_y = \frac{\exp(q_y/\tau)}{\sum_{y' \in \cy}\exp(q_{y'}/\tau)}
          \]

          Additionally, we define \( \argmax(q) \in P(\cy) \) to be the uniform distribution over the maximal values of
          \( q \),
          namely
          <div class="largescreen">
            \[

            \argmax{q} = \begin{cases}
            1/|{Y_q}| & \mathrm{if}~y \in Y_q \\
            0 & \mathrm{if}~y \notin Y_q
            \end{cases}, ~~~\mathrm{where}~~~ Y_q = \{y \in \cy ~:~q_y = \max(q)\}

            \]
          </div>

          <div class="smallscreen">
            \[

            \argmax{q} = \begin{cases}
            1/|{Y_q}| & \mathrm{if}~y \in Y_q \\
            0 & \mathrm{if}~y \notin Y_q
            \end{cases},\] <br />
            \[ ~~~\mathrm{where}~~~ Y_q = \{y \in \cy ~:~q_y = \max(q)\}

            \]
          </div>
          Now, define \( \hat{f}_\tau \) to be the temperature sampling of \( \hat{f} \), i.e.

          \[

          \hat{f}_\tau(\cdot|x)
          =
          \softmax(\hat{f}
          (\cdot|x);\tau)

          \]

          and \( \hat{f}_{\max} \) the arg-max ''sampling'' of \( \hat{f} \), i.e.

          \[
          \hat{f}_{\max}(\cdot|x) =
          \argmax(\hat{f}(\cdot|x)).

          \]

          We prove in the paper that if the arg-max predictor \( \hat{f}_{\max} \) is better than
          the best
          expert,
          then ORBITS is possible with low-temperature sampling.


          Assume that \( R_{\ptest}(\hat{f}_{\max}) > \max_{i \in [k]} R_{\ptest}(f_i) \), then there exists some
          temperature \( \tau
          \in (0,1) \) s.t. for all \( 0 \le \tau' \le \tau \) it holds that.

          \[
          R_{\ptest}(\hat{f}_{\tau'}) > \max_{i \in [k]} R_{\ptest}(f_i)
          \]



        </div>

      </div>
      <h3>ORBITS is possible with Diverse Datasets</h3>
      <div class="columns ">
        <div class="column is-full-width">

          Our theory requires dataset diversity as a
          necessary condition for enabling ORBITS. As shown in the first figure, not all
          models are able to transcend. Unlike ChessFormer 1000 or 1300, the Chessformer 1500 fails to transcend. We
          hypothesize that this is due to the fact that in the band of ratings from 1000 to 1500, diversity does not
          significantly increase. If this is true, a 1000 rated player can be thought of as a noisy 1500 rated
          player, but a 1500 rated player cannot be thought of as a noisy 2000 rated player.

          We explore this research question by quantifying dataset diversity through
          the normalized entropy on the action distribution:
          <span class="largescreen">
            $$\mathcal{H}_f(Y | X)= {\mathbb{E}_{y \sim
            f(y|x=X)}[-\log_2
            f(y | x=X)]}/{\log_2 |\mathcal{Y}|}$$
          </span>

          <span class="smallscreen">
            \[

            \mathcal{H}_f(Y | X)=\\
            {\mathbb{E}_{y \sim
            f(y|x=X)}[-\log_2
            f(y | x=X)]}/{\log_2 |\mathcal{Y}|}

            \]
          </span>

          To
          gain intuition for this metric, imagine the action distribution of
          moves taken for any given state. Entropy will be higher for more uniform action distributions, and lower for
          more deterministic, peaked action distributions. The average entropy of these action distributions can
          therefore serve as a measurement of the diversity of the dataset. We normalize this entropy to the range \([0,
          1]\) by dividing by the binary log of the number of legal moves: \(\log_2 |\mathcal{Y}|\).

          Importantly, we cannot calculate this normalized entropy for every state, as most states after move 16 in
          the midgame and before the engame are unique within the dataset and we therefore observe just a single action
          for thus states. Therefore our metric is limited in that it only considers opening moves, the beginning of the
          midgame, and the endgame. We consider only common states with greater than 100 actions by sampling
          1,000,000 games from each dataset. The average entropy confirm our hypothesis: The &lt; 1500 cut off dataset
          has on average less diversity than the &lt; 1300 dataset, which has is again less than the &lt; 1000 dataset.
          This points towards answering our research question in the affirmative; Chessformer 1500 likely is not
          transcendent due to a lack of diversity in its dataset. If the entropy stayed constant for each dataset,
          this would imply a similar level of diversity for each. In such a case, we would expect that ChessFormer
          1500 likely would also transcend. Instead, as predicted, Chessformer 1500 likely is not transcendent due
          to a lack of diversity in its dataset.
        </div>
      </div>
      <div class='entropy'>
        <div class="columns is-centered has-text-centered" style="margin-top: 15px; flex-shrink: 0;">
          <div class="column is-full-width">
            <img style="width: 400px;" src="./static/images/entropy_of_action_distribution_over_common_states.png"
              alt="chart">
          </div>
          <br />
        </div>
        Action distribution diversity, as measured by the average normalized entropy over different chess
        rating dataset cutoffs with n = 2681, 3037, 3169 common states for ratings 1000, 1300, 1500, respectively.
        These entropies are calculated directly from the empiricial frequencies of our dataset, and are model-agnostic.

      </div>

    </div>

    <div class="container is-max-desktop content">
      <h2 class="title is-3">t-SNE Embeddings of ChessFormer</h2>
      Try zooming in by right clicking on the image, and click "Open Image in New Tab".


      Inspired by <a href="https://www.nature.com/articles/nature14236" target="_blank"> Deep Q-Networks (DQN) </a>,
      we
      generate a <a href="https://distill.pub/2016/misread-tsne/" target="_blank">t-SNE embedding</a> of ChessFormer's
      last
      hidden
      layer latent representations of game transcripts during training time. The colors represent the probability of
      winning,
      with +1 corresponding to a state where White has won and -1 to Black. We also visualize several board states
      associated different clusters within the t-SNE embedding, and their associated expected reward when following
      the
      expert
      Stockfish distribution.

      <div class="columns is-centered has-text-centered" style="margin: 15px 0;">
        <div class="column is-full-width">
          <img style="margin: 15px 0" src="./static/images/latent_board_state_reward_tsne.png" alt="chart">
        </div>
        <br />
      </div>

      Here, we generate a t-SNE embedding of
      ChessFormer's last hidden layer latent representations of game transcripts during training time. The colors
      represent the probability of winning, with +1 corresponding to a state where White has won and 0 to Black.
      Probabiliy of winning is computed through the Stockfish analysis engine. We also visualize several board states
      associated with different clusters in the t-SNE embedding, and their associated expected reward when following the
      expert Stockfish distribution. Note that the model distinguishes between states where the outcome has already been
      determined (the two left boards), versus opening states that are extremely similar (the two right boards).


      <div class="columns is-centered has-text-centered" style="margin: 15px 0;">
        <div class="column is-full-width">
          <img style="margin: 15px 0" src="./static/images/latent_board_state_tsne_0_1.png" alt="chart">
        </div>
        <br />
      </div>

      We visualize the full TSNE again here, but this time coloring by game length rather than reward. We see that
      games
      with high reward tend to be longer, which makes logical sense as the result of the game will tend to be clearer
      as
      the game proogresses.
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <img style="margin: 15px 0" src="./static/images/latent_board_state_game_len_tsne.png" alt="chart">
        </div>
        <br />
      </div>

    </div>

    <div class="container is-max-desktop content">
      <h2 class="title is-3">Additional Denoising Visualizations</h2>
      Here, we illustrate the importance of denoising. In the image below, denoising helps black find the only correct
      move. White has pinned the black rook to
      the Queen: any move where the rook does not move to e4 results in a heavy loss of material. As \(\tau\)
      decreases,
      the expected reward increases substantially and converges onto the correct move.
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <img style="margin: 15px 0" src="./static/images/denoising_viz1.png" alt="chart">
        </div>
        <br />
      </div>
      <br /> <br />

      Another example where denoising helps avoid errors. Moving the queen to either d1 or h1 takes a bishop or rook,
      respectively, but loses the queen in the following turn. While queen to e5 does not put the queen in immediate
      danger,
      it allows white to push the pawn on f3 to d3, where it threatens the queen and is protected by the bishop on c1.
      The queen then must move out of danger, losing its opportunity to take the free pawn on h4 and giving white
      valuable space towards the center of the board. As \(\tau\) decreases, the expected reward converges to the move
      queen to d4, taking the pawn and checking the black king.
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <img style="margin: 15px 0" src="./static/images/denoising_viz2.png" alt="chart">
        </div>
        <br />
      </div>
      <br /> <br />
      In this setup, a higher temperature shows two plausible moves for the black rook: g1 or f1. As the temperature
      decreases, the expected reward converges to g1. If the black rook were to move to f1, the white rook would take
      the black rook, blocking the black pawn on f2 from promoting and protecting the promotion square from the
      h2 pawn. If the rook were to move to g1, on the other hand, it would open the promotion square from the h2 pawn
      without being at any immediate risk. If white responded by moving its bishop to g2, protecting the promotion
      squares
      from both of the advanced black pawns, black could respond by taking the rook on a1, gaining significant material.
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <img style="margin: 15px 0" src="./static/images/denoising_viz3.png" alt="chart">
        </div>
        <br />
      </div>
      <br /> <br />

    </div>
    <div class="container is-max-desktop content">
      <h2 class="title is-3">Intuition of Low Temperature Sampling Inducing ORBITS</h2>
      To build intuition for the primary mechanism of ORBITS that we explore in this work, we give the following
      toy progression of distributions in order to clearly illustrate how low-temperature sampling can induce
      ORBITS through majority voting. Here, the middle purple action represents the correct, high-reward output,
      whilst the left and right actions are low-reward, suboptimal outputs. We plot the probability of each output as a
      label on
      the x axis.
      <br /> <br />

      The first expert output distribution. Although it puts non-negligible mass on the purple, high-reward
      action, it still samples a low-reward action the majority of the time.
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <img style="margin: 15px 0" src="./static/images/intuition1.png" alt="chart">
        </div>
        <br />
      </div>
      <br /> <br />

      The second expert output distribution. Symmetric to the first expert, it also puts non-negligible mass
      on the purple, high-reward action. However, it samples a low-reward action the majority of the time on the right.
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <img style="margin: 15px 0" src="./static/images/intuition2.png" alt="chart">
        </div>
        <br />
      </div>
      <br /> <br />
      By taking the average of the first and second experts, we observe that this distribution now puts the majority of
      mass onto the correct action.
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <img style="margin: 15px 0" src="./static/images/intuition3.png" alt="chart">
        </div>
        <br />
      </div>
      <br /> <br />
      Finally, by setting temperature \(\tau\) to be &lt;1, more weight is shifted towards the high probability action,
      leading to a gain in the expected reward.
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <img style="margin: 15px 0" src="./static/images/intuition4.png" alt="chart">
        </div>
        <br />
      </div>
      <br /> <br />
    </div>

    </div>
  </section>



  <section class="section">
    <div class="container is-max-desktop">

      <!-- Concurrent Work. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Related Work</h2>

          <div class="content has-text-justified">
            <p>
              This project is built on some exceptional prior projects and platforms, which we are extraordinarily
              grateful for.
              In no particular order, these include
              <a href="https://database.lichess.org">Lichess</a>, our dataset source,
              <a href="https://adamkarvonen.github.io/machine_learning/2024/01/03/chess-world-models.html">Adam
                Karvonen's codebase for training chess models</a> and the
              <a href="https://stockfishchess.org/">StockFish chess engine</a>.


            </p>

          </div>
        </div>
      </div>
      <!--/ Concurrent Work. -->

    </div>
  </section>



  </div>
  </section>
  



  <footer class="footer">
    <div class="container">

      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p style="text-align: center
            ">
              Website templated borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies.</a>
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
